{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we look at using a simple model built off a custom keras layer that computes anisotropic magnitudes of\n",
    "the gradient. These anisotropic magnitude transformations are non-linear. Their directions and sizes are both trainable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of Data Files\n",
    "\n",
    "The dataset is from [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/). The decription of the file formats\n",
    "is also given there.\n",
    "\n",
    "## Image File Format\n",
    "```\n",
    "[offset] [type]          [description] \n",
    "0000     32 bit integer  magic number \n",
    "0004     32 bit integer  number of images \n",
    "0008     32 bit integer  number of rows \n",
    "0012     32 bit integer  number of columns \n",
    "0016     unsigned byte   pixel \n",
    "0017     unsigned byte   pixel \n",
    "........ \n",
    "xxxx     unsigned byte    pixel\n",
    "```\n",
    "\n",
    "## Label File Format\n",
    "```\n",
    "[offset] [type]          [description] \n",
    "0000     32 bit integer  magic number (MSB first) \n",
    "0004     32 bit integer  number of items \n",
    "0008     unsigned byte   label \n",
    "0009     unsigned byte   label \n",
    "........ \n",
    "xxxx     unsigned byte   label\n",
    "The labels values are 0 to 9.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct # To unpack string literals of bytes to integers.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from my_src import my_layers\n",
    "plt.rcParams['svg.fonttype'] = 'none' # Saves space when saving svg plots to file.\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {}\n",
    "y = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training images information.\n",
    "\n",
    "with open('data/train-images.idx3-ubyte', 'rb') as f:\n",
    "    _ = f.read(4) # Read the magic number.\n",
    "    training_info = {name : f.read(4) for name in ['n_images', 'n_rows', 'n_columns']}\n",
    "    print(training_info)\n",
    "    # Make sure to enforce big-endian.\n",
    "    training_info = {key : struct.unpack('>i', value)[0] for key, value in training_info.items()}\n",
    "    print(training_info)\n",
    "    \n",
    "    images = np.fromfile(f, dtype = 'uint8')\n",
    "    images = images.reshape(training_info['n_images'], training_info['n_rows'], training_info['n_columns'])\n",
    "X['train'] = images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training labels.\n",
    "\n",
    "with open('data/train-labels.idx1-ubyte', 'rb') as f:\n",
    "    _ = f.read(4) # Read the magic number.\n",
    "    training_info['n_labels'] = struct.unpack('>i', f.read(4))[0]\n",
    "    print(training_info)\n",
    "        \n",
    "    labels = np.fromfile(f, dtype = 'uint8')\n",
    "y['train'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y['train'], return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the test images.\n",
    "\n",
    "with open('data/t10k-images.idx3-ubyte', 'rb') as f:\n",
    "    _ = f.read(4) # Read the magic number.\n",
    "    testing_info = {name : f.read(4) for name in ['n_images', 'n_rows', 'n_columns']}\n",
    "    print(testing_info)\n",
    "    # Make sure to enforce big-endian.\n",
    "    testing_info = {key : struct.unpack('>i', value)[0] for key, value in testing_info.items()}\n",
    "    print(testing_info)\n",
    "    \n",
    "    images = np.fromfile(f, dtype = 'uint8')\n",
    "    images = images.reshape(testing_info['n_images'], testing_info['n_rows'], testing_info['n_columns'])\n",
    "X['test'] = images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training labels.\n",
    "\n",
    "with open('data/t10k-labels.idx1-ubyte', 'rb') as f:\n",
    "    _ = f.read(4) # Read the magic number.\n",
    "    testing_info['n_lables'] = struct.unpack('>i', f.read(4))[0]\n",
    "    print(testing_info)\n",
    "        \n",
    "    labels = np.fromfile(f, dtype = 'uint8')\n",
    "y['test'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anisotropic Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to construct layers of the complete model.\n",
    "import importlib\n",
    "importlib.reload(my_layers)\n",
    "\n",
    "def make_simple_model(n_directions, input_shape):\n",
    "    inputs = tf.keras.Input(shape = input_shape)\n",
    "    x = tf.keras.layers.Reshape(target_shape = input_shape + (1,),\n",
    "                                name = 'Form_Channel')(inputs)\n",
    "    grads = my_layers.AnisotropicGrad2D(n_directions,\n",
    "                                        name = 'Anisotropic_Grads')(x)\n",
    "    grads = tf.keras.layers.Permute((4, 3, 2, 1))(grads)\n",
    "    grads = tf.keras.layers.Reshape(target_shape = (n_directions, grads.shape[-1] * grads.shape[-2]))(grads)\n",
    "    \n",
    "    # Instead of taking mean do a more general dense connection.\n",
    "    grads = tf.keras.layers.Dense(units = 1,\n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2())(grads)\n",
    "    \n",
    "    # Need to use a Lambda Layer as inputs between layers in keras functional api needs to be keras layers.\n",
    "    mean_over_image = tf.keras.layers.Lambda(lambda X : tf.keras.backend.mean(X, axis = [1, 2]),\n",
    "                                             name = 'Mean_Over_Image')\n",
    "    #grads = mean_over_image(grads)\n",
    "    mean = mean_over_image(x)\n",
    "    mean = tf.keras.layers.Reshape(target_shape = (mean.shape[-1], 1))(mean)\n",
    "    x = tf.keras.layers.concatenate([mean, grads], axis = -2)\n",
    "    x = tf.keras.layers.Reshape(target_shape = (x.shape[1] * x.shape[2],))(x)\n",
    "    class_probs = tf.keras.layers.Dense(units = 10,\n",
    "                                        activation = tf.nn.softmax,\n",
    "                                        kernel_regularizer = tf.keras.regularizers.l2(),\n",
    "                                        name = 'Predictions')(x)\n",
    "    model = tf.keras.Model(inputs = inputs, outputs = class_probs)\n",
    "    return model\n",
    "    \n",
    "    \n",
    "    \n",
    "def make_model(n_directions, n_filters, input_shape):\n",
    "    inputs = tf.keras.Input(shape = input_shape)\n",
    "    x = tf.keras.layers.Reshape(target_shape = input_shape + (1,),\n",
    "                                name = 'Form_Channel')(inputs)\n",
    "    x = my_layers.AnisotropicGrad2D(n_directions,\n",
    "                                    name = 'Anisotropic_Grads')(x)\n",
    "    x = tf.keras.layers.Reshape(target_shape = (input_shape[0] - 1, input_shape[1] - 1, n_directions,),\n",
    "                                name = 'Flatten_Grads')(x)\n",
    "    x = tf.keras.layers.Conv2D(filters = n_filters,\n",
    "                               kernel_size = 4,\n",
    "                               kernel_regularizer = tf.keras.regularizers.l2(),\n",
    "                               name = 'conv2d')(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size = 4)(x)\n",
    "    x = tf.keras.layers.Reshape(target_shape = (x.shape[1] * x.shape[2] * x.shape[3],))(x)\n",
    "    class_probs = tf.keras.layers.Dense(units = 10, \n",
    "                                        activation = tf.nn.softmax,\n",
    "                                        kernel_regularizer = tf.keras.regularizers.l2(),\n",
    "                                        name = 'Prediction')(x)\n",
    "    model = tf.keras.Model(inputs = inputs, outputs = class_probs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_simple_model(n_directions = 5, input_shape = X['train'].shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_simple_model(n_directions = 16, input_shape = X['train'].shape[1:])\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "model.fit(X['train'], y['train'], epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X['test'], y['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in model.trainable_weights[:2]:\n",
    "    print(w)\n",
    "    plt.plot(tf.keras.backend.eval(w))\n",
    "    plt.show()\n",
    "grad_reduce_w = tf.keras.backend.eval(model.trainable_weights[2])\n",
    "print(grad_reduce_w.reshape(27, 27).shape)\n",
    "plt.imshow(grad_reduce_w.reshape(27,27))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "prediction_w = model.trainable_weights[-2]\n",
    "print(prediction_w)\n",
    "plt.imshow(tf.keras.backend.eval(prediction_w))\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(5, 16, X['train'].shape[1:])\n",
    "print(model(X['train'][:2]).shape)\n",
    "print(tf.keras.backend.eval(model(X['train'][:2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(n_directions = 16, n_filters = 16, input_shape = X['train'].shape[1:])\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "model.fit(X['train'], y['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X['test'], y['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in model.layers[2]._trainable_weights:\n",
    "    print(x)\n",
    "    print(tf.keras.backend.eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
